<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · IFGF.jl</title><script data-outdated-warner src="assets/warner.js"></script><link rel="canonical" href="https://WaveProp.github.io/IFGF.jl/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>IFGF.jl</a></span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a><ul class="internal"><li><a class="tocitem" href="#introduction-section"><span>Introduction</span></a></li><li><a class="tocitem" href="#custom-kernel-section"><span>Custom kernels</span></a></li><li><a class="tocitem" href="#Advanced-usage"><span>Advanced usage</span></a></li></ul></li><li><a class="tocitem" href="references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/WaveProp/IFGF.jl/blob/master/docs/src/index.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="home-section"><a class="docs-heading-anchor" href="#home-section">IFGF.jl</a><a id="home-section-1"></a><a class="docs-heading-anchor-permalink" href="#home-section" title="Permalink"></a></h1><p><em>A pure Julia implementation of the Interpolated Factored Green Function Method on adaptive trees</em></p><h2 id="introduction-section"><a class="docs-heading-anchor" href="#introduction-section">Introduction</a><a id="introduction-section-1"></a><a class="docs-heading-anchor-permalink" href="#introduction-section" title="Permalink"></a></h2><p>This package implements an algorithm for approximating the forward map (i.e. the matrix-vector product) of certain kernel matrices, where <strong>kernel matrix</strong> will be used to refer to any matrix <span>$A \in \mathbb{F}^{m\times n}$</span> whose entries can be computed from the following three components: </p><ul><li>a vector of target elements <span>$X = \left\{ \boldsymbol{x}_i \right\}_{i=1}^m$</span> </li><li>a vector of source elements <span>$Y = \left\{ \boldsymbol{y}_i \right\}_{i=1}^n$</span> </li><li>a kernel function <span>$K(x,y) : X \times Y \to \mathbb{F}$</span>, where <span>$\mathbb{F}$</span> is the return type of the kernel (and of the underlying matrix)</li></ul><p>The entries of a kernel matrix are given by the explicit formula <span>$A_{i,j} = K(\boldsymbol{x}_i,\boldsymbol{y}_j)$</span>. Typically, <span>$X$</span> and <span>$Y$</span> are vectors of points in <span>$\mathbb{R}^d$</span>, and <span>$K$</span> is a function mapping pairs of points into <span>$\mathbb{R}$</span> or <span>$\mathbb{C}$</span>. </p><p>Provided <span>$K$</span> has sufficient structure, an approximation of the product <span>$Ax$</span> can be computed in linear or log-linear complexity by various well known algorithms such as the <em>Fast Multipole Method</em> or <em>hierarchical matrices</em>; this package implements another acceleration algorithm named <em>Interpolated Factored Green Function</em> method.</p><p>The main structure exported by this package is the <code>IFGFOp{T}</code>, which inherits from <code>AbstractMatrix{T}</code> and supports some basic linear algebra operations. To construct an <code>IFGFOp</code> you will need to specify a kernel <code>K</code>, the target elements <code>X</code>, and the source elements <code>Y</code>. You may also need to pass some problem-specific information regarding <code>K</code>. </p><p>To illustrate how to set up the <code>IFGFOp</code>, let <span>$X$</span> and <span>$Y$</span> be a set of random points on the unit cube, and take <span>$K$</span> to be the Helmholtz Green function in three dimensions:</p><p class="math-container">\[    K(\boldsymbol{x},\boldsymbol{y}) = \frac{e^{ik|\boldsymbol{x}-\boldsymbol{y}|}}{4\pi |\boldsymbol{x}-\boldsymbol{y}|}\]</p><p>Setting up the aforementioned kernel matrix can be done as follows:</p><pre><code class="language-julia hljs">using IFGF, LinearAlgebra, StaticArrays
import IFGF: wavenumber

# random points on a cube
const Point3D = SVector{3,Float64}
m,n = 100_000, 100_000
X,Y = rand(Point3D,m), rand(Point3D,n)

# define a the kernel matrix
struct HelmholtzMatrix &lt;: AbstractMatrix{ComplexF64}
    X::Vector{Point3D}
    Y::Vector{Point3D}
    k::Float64
end

# indicate that this is an ocillatory kernel with wavenumber `k`
wavenumber(A::HelmholtzMatrix) = A.k

# functor interface
function (K::HelmholtzMatrix)(x,y)
    k = wavenumber(K)
    d = norm(x-y)
    exp(im*k*d)*inv(4*pi*d)
end

# abstract matrix interface
Base.size(A::HelmholtzMatrix) = length(X), length(Y)
Base.getindex(A::HelmholtzMatrix,i::Int,j::Int) = A(A.X[i],A.Y[j])

# create the abstract matrix
k = 8π
A = HelmholtzMatrix(X,Y,k)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">100000×100000 Main.HelmholtzMatrix:
 -0.00685517-0.0668924im  …    -0.0569299-0.0664648im
   -0.103151-0.0666959im       -0.0759449-0.0459245im
  -0.0464392-0.0735239im        -0.127411+0.00151087im
  -0.0907876+0.0109399im        0.0271012-0.110902im
    0.158783+0.0040284im        0.0968854+0.0379255im
   0.0586389-0.0574775im  …    -0.0571985-0.0662535im
   0.0130289-0.0652858im         0.321177-0.0822165im
  -0.0595217-0.0643535im     -0.000843506+0.0748601im
  -0.0859715-0.0257891im        -0.116034-0.0448555im
   0.0356727-0.107905im         0.0401748-0.106015im
            ⋮             ⋱  
   0.0122234+0.141811im         -0.127569+0.0100555im
  -0.0355077+0.0893647im         0.258135+0.142173im
  -0.0907412+0.0115377im        0.0675232+0.0389552im
  -0.0232255-0.0637052im         0.157951+0.0106334im
    0.106124-0.0109096im  …    -0.0585052+0.0425543im
   0.0528788-0.0377006im        0.0404561+0.0649188im
  -0.0897826-0.0109418im        -0.166481-0.110453im
    0.321578-0.0283171im         0.106179-0.00168166im
   0.0783546-0.0174679im      -0.00132668+0.0978675im</code></pre><p>Note that <code>A</code> is a lazy <span>$100000 \times 100000$</span> matrix which computes its entries on demand; as such, it has a light memory footprint. Trying to instantiate the underlying <code>Matrix{ComplexF64}</code> would most likely result in you running out of memory.</p><p>To build an approximation of <code>A</code> using the <code>IFGFOp</code>, you may use the high-level constructor <a href="references/#IFGF.assemble_ifgf-Tuple{Any, Any, Any}"><code>assemble_ifgf</code></a> as follows:</p><pre><code class="language-julia hljs">L = assemble_ifgf(A,X,Y;tol=1e-3)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">IFGFOp of ComplexF64 with range 1:100000 × 1:100000
	 number of nodes:                2047
	 number of leaves:               1024
	 number of active cones:         179452
	 maximum number of active cones: 503
</code></pre><p>Check the documentation of <a href="references/#IFGF.assemble_ifgf-Tuple{Any, Any, Any}"><code>assemble_ifgf</code></a> for more information on the available options. Note that <code>L</code>, while not as compact as <code>A</code>, still has a relatively light memory footprint:</p><pre><code class="language-julia hljs">mbytes = Base.summarysize(L) / 1e6
print(&quot;Size of L: $mbytes megabytes&quot;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Size of L: 36.661984 megabytes</code></pre><div class="admonition is-info"><header class="admonition-header">Info</header><div class="admonition-body"><p>To approximate oscillatory kernels, the <code>IFGF</code> algorithm adapts to the acoustic size of each of the cells in the source tree in order to keep the interpolation error constant across all levels of the tree. In practice, this means that memory and runtime will depend on both the total number of points <code>n</code> and on the wavenumber <code>k</code>, with smaller <code>k</code> being &quot;easier&quot; to approximate.</p></div></div><p>We can use <code>L</code> in lieu of <code>A</code> to approximate the matrix vector product, as illustrated below:</p><pre><code class="language-julia hljs">x     = randn(ComplexF64,n)
y     = L*x</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">100000-element Vector{ComplexF64}:
  -40.30770724779544 - 36.282838547078065im
   19.55007680935604 - 62.17510636326251im
 -15.434860717752908 - 0.3922166010035699im
 -132.08342008016334 + 7.775392737438748im
 -3.7121400129125712 - 12.093674333836026im
   40.37325895191082 + 40.613244399387334im
 -16.643864801075857 + 32.31369120960893im
   7.097950035634436 - 69.58244714551807im
  -146.8602137034202 - 107.36372474221069im
  1.4281423547714946 - 39.361662833543335im
                     ⋮
  22.689612577941247 - 0.019501769494676413im
  17.435713313716455 - 23.668910846592716im
  20.040540277275923 + 46.2513165558736im
  -35.77449751181919 - 8.017614459440509im
  29.943129193458645 - 37.08607267738165im
  -80.34283012208415 - 45.9711057298677im
  29.267602900318707 + 9.13110119314889im
   -20.5277027873903 - 8.205616670978678im
   88.58374856785778 - 5.789445177128644im</code></pre><p>The quality of the approximation may be verified by computing the exact value at a few randomly selected set of indices:</p><pre><code class="language-julia hljs">I     = rand(1:m,100)
exact = [sum(A[i,j]*x[j] for j in 1:n) for i in I] # matrix-vector product
er    = norm(y[I]-exact) / norm(exact) # relative error
print(&quot;approximate relative error: $er&quot;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">approximate relative error: 0.00026267647601079577</code></pre><div class="admonition is-success"><header class="admonition-header">Kernel optimizations</header><div class="admonition-body"><p>To keep things simple in this example, we neglected some important optimizations that can be performed when defining your own kernel. In particular, you can overload some default (generic) methods for your own kernel to provide e.g. a vectorized evaluation using <code>SIMD</code> instructions. We also avoided the possible issue of kernel blowing up at <span>$\boldsymbol{x} = \boldsymbol{y}$</span>. See the the <a href="https://github.com/WaveProp/IFGF.jl/blob/main/test/testutils.jl"><code>test/testutils.jl</code></a> file for an optimized definition of some classical kernels, or the <a href="#custom-kernel-section">Custom kernels</a> section for a discussion on what methods can be overloaded.</p></div></div><h2 id="custom-kernel-section"><a class="docs-heading-anchor" href="#custom-kernel-section">Custom kernels</a><a id="custom-kernel-section-1"></a><a class="docs-heading-anchor-permalink" href="#custom-kernel-section" title="Permalink"></a></h2><p>When defining your own kernel matrix, there is one required as well as some optional methods to overload in order to provide kernel-specific information to the <code>IFGFOp</code> constructor. The table below summarizes the interface methods, where <code>Y</code> is a <code>SourceTree</code>, <code>x</code> is an <code>SVector</code> representing a point, and <code>K</code> is your custom kernel:</p><table><tr><th style="text-align: right"><strong>Method&#39;s name</strong></th><th style="text-align: right"><strong>Required</strong></th><th style="text-align: right"><strong>Brief description</strong></th></tr><tr><td style="text-align: right"><a href="references/#IFGF.wavenumber"><code>wavenumber(K)</code></a></td><td style="text-align: right">Yes</td><td style="text-align: right">Return the wavenumber of your kernel</td></tr><tr><td style="text-align: right"><code>return_type(K)</code></td><td style="text-align: right">No</td><td style="text-align: right">Type of element returned by <code>K(x,y)</code></td></tr><tr><td style="text-align: right"><a href="references/#IFGF.centered_factor-Tuple{Any, Any, Any}"><code>centered_factor(K,x,Y)</code></a></td><td style="text-align: right">No</td><td style="text-align: right">A representative value of <code>K(x,y)</code> for <code>y ∈ Y</code></td></tr><tr><td style="text-align: right"><a href="references/#IFGF.inv_centered_factor-Tuple{Any, Any, Any}"><code>inv_centered_factor(K,x,Y)</code></a></td><td style="text-align: right">No</td><td style="text-align: right">A representative value of <code>inv(K(x,y))</code> for <code>y ∈ Y</code></td></tr><tr><td style="text-align: right"><a href="references/#IFGF.transfer_factor-Tuple{Any, Any, Any}"><code>transfer_factor(K,x,Y)</code></a></td><td style="text-align: right">No</td><td style="text-align: right">Transfer function given by <code>inv_centered_factor(K,x,parent(Y))*centered_factor(K,x,Y)</code></td></tr><tr><td style="text-align: right"><a href="references/#IFGF.near_interaction!-NTuple{7, Any}"><code>near_interaction!(C,K,X,Y,σ,I,J)</code></a></td><td style="text-align: right">No</td><td style="text-align: right">Compute <code>C[i] &lt;- C[i] + ∑ⱼ K(X[i],Y[j])*σ[j]</code> for <code>i ∈ I</code>, <code>j ∈ J</code></td></tr></table><p>Because the <code>IFGF</code> algorithms must adapt its interpolation scheme depending on the frequency of oscillations to control the interpolation error, you must extend the <code>IFGF.wavenumber</code> method. If the kernel is not oscillatory (e.g. exponential kernel, Newtonian potential), simply return <code>0</code>.</p><p>The <code>return_type</code> method will be used to infer the type of the underlying abstract matrix. By default, it will use <code>Base.promote_op</code> to try and infer a return type, but you may force that type manually if needed by extending this method.</p><p>The <code>centered_factor</code>, <code>inv_centered_factor</code>, and <code>transfer_factor</code> have reasonable defaults, and typically are overloaded only for performance reasons (e.g. if some analytic simplifications are available).</p><p>Finally, the <code>near_interaction</code> method is called at the leaves of the source tree to compute, well, the near interactions. Extending this function to make use of e.g. SIMD instructions can significantly speed up some parts of the code.</p><p>To illustrate how to define a new kernel with the aforementioned hooks, we will first extend the definition of the <code>HelmholtzMatrix</code> (done in the <a href="#introduction-section">introduction</a>) by implementing a vectorized <code>near_interaction</code> method using the <code>LoopVectorization</code> package. The code below, though more complex, implements a vectorized evaluation of the dense forward map:</p><pre><code class="language- hljs">using LoopVectorization

function IFGF.near_interaction!(C,K::HelmholtzMatrix,X,Y,σ,I,J)
    Tx = eltype(X)
    Ty = eltype(Y)
    @assert Tx &lt;: SVector &amp;&amp; Ty &lt;: SVector
    Xm = reshape(reinterpret(eltype(Tx),X),3,:)
    Ym = reshape(reinterpret(eltype(Ty),Y),3,:)
    @views helmholtz3d_sl_vec!(C[I],Xm[:,I],Ym[:,J],σ[J],K.k)
end

function helmholtz3d_sl_vec!(C::AbstractVector{Complex{T}},X,Y,σ,k) where {T}
    @assert eltype(σ) == eltype(C)
    m,n = size(X,2), size(Y,2)
    C_T = reinterpret(T, C)
    C_r = @views C_T[1:2:end,:]
    C_i = @views C_T[2:2:end,:]
    σ_T = reinterpret(T, σ)
    σ_r = @views σ_T[1:2:end,:]
    σ_i = @views σ_T[2:2:end,:]
    @turbo for j in 1:n # LoopVectorization magic
        for i in 1:m
            d2 = (X[1,i] - Y[1,j])^2
            d2 += (X[2,i] - Y[2,j])^2
            d2 += (X[3,i] - Y[3,j])^2
            d  = sqrt(d2)
            s, c = sincos(k * d)
            zr = inv(4π*d) * c
            zi = inv(4π*d) * s
            C_r[i] += (!iszero(d))*(zr*σ_r[j] - zi*σ_i[j])
            C_i[i] += (!iszero(d))*(zi*σ_r[j] + zr*σ_i[j])
        end
    end
    return C
end</code></pre><p>The other optimization that we can perform for the <code>HelmhotlzMatrix</code> is to rewrite the <a href="references/#IFGF.transfer_factor-Tuple{Any, Any, Any}"><code>transfer_factor</code></a> so that it uses only one exponential. The default definition of <code>transfer_factor(K,x,Y)</code> simply divides <code>K(x,yc)</code> by <code>K(x,yp)</code>, where <code>yc</code> is the center of the source box <code>Y</code> and <code>yp</code> is the center of the parent of <code>Y</code>. This division can be simplified to avoid computing two complex exponentials as follows:</p><pre><code class="language-julia hljs">function IFGF.transfer_factor(K::HelmholtzMatrix,x,Y)
    yc  = IFGF.center(Y)
    yp  = IFGF.center(IFGF.parent(Y))
    d   = norm(x-yc)
    dp  = norm(x-yp)
    exp(im*K.k*(d-dp))*dp/d
end</code></pre><p>We can check that the result is still correct with the code below:</p><pre><code class="language-julia hljs">y     = L*x
er    = norm(y[I]-exact) / norm(exact) # relative error
print(&quot;approximate relative error: $er&quot;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">approximate relative error: 0.00026267647601081084</code></pre><p>Of course, you should benchmark your code (with your specific kernel) to see if and when it may be useful to provide faster versions of these methods.</p><div class="admonition is-info"><header class="admonition-header">Tensor-valued kernels</header><div class="admonition-body"><p>Everything said so far applies if <code>K</code> returns a tensor instead of a scalar. This is the case e.g. for the dyadic Green function for time-harmonic Maxwell&#39;s equations, given by</p><p class="math-container">\[    K(\boldsymbol{x},\boldsymbol{y}) = \mathbb{G}(\boldsymbol{x}, \boldsymbol{y}) := \left(\mathbb{I}+\frac{\nabla_{\boldsymbol{x}} \nabla_{\boldsymbol{x}}}{k^{2}}\right) G(\boldsymbol{x}, \boldsymbol{y}),\]</p><p>where <span>$k$</span> is a constant which depends on the electric permittivity, the magnetic permeability, and the angular frequency, and where</p><p class="math-container">\[G(\boldsymbol{x},\boldsymbol{y}) = \frac{e^{ik|\boldsymbol{x}-\boldsymbol{y}|}}{4\pi |\boldsymbol{x}-\boldsymbol{y}|},\]</p><p>is the Helmholtz Green&#39;s function.</p><p>Defining for example a <code>MaxwellKernel</code> as done below, and calling the <code>assemble_ifgf</code> constructor, should work as expected. Note that, for performance reasons, tensor-valued kernels will typically return a <code>StaticArray</code>.</p><pre><code class="language- hljs">
using IFGF, StaticArrays, LinearAlgebra

struct MaxwellKernel
    k::Float64
end

function (K::MaxwellKernel)(x,y)
    r   = x - y
    d   = norm(r)
    # helmholtz greens function
    g   = exp(im*K.k*d)/(4π*d)
    gp  = im*K.k*g - g/d
    gpp = im*K.k*gp - gp/d + g/d^2
    RRT = r*transpose(r) # rvec ⊗ rvecᵗ
    G   = g*LinearAlgebra.I + 1/K.k^2*(gp/d*LinearAlgebra.I + (gpp/d^2 - gp/d^3)*RRT)
    return (!iszero(d))*G
end
import IFGF: wavenumber
wavenumber(K::MaxwellKernel) = K.k</code></pre></div></div><h2 id="Advanced-usage"><a class="docs-heading-anchor" href="#Advanced-usage">Advanced usage</a><a id="Advanced-usage-1"></a><a class="docs-heading-anchor-permalink" href="#Advanced-usage" title="Permalink"></a></h2><p>The <a href="references/#IFGF.assemble_ifgf-Tuple{Any, Any, Any}"><code>assemble_ifgf</code></a> provides a high-level constructor for the <code>IFGFOp</code> structure by making various default choices of clustering algorithms, admisibility condition, how the interpolation cones should be created, etc. To obtain a more granular control over these parameters, you have to create them independently and pass them to the (default) <a href="@ref"><code>IFGF</code></a> constructor</p><p>Resuming the example for the Helmholtz kernel, we will go over all the steps to manually construct the fields of the <code>IFGFOp</code>.</p><h3 id="Target-tree"><a class="docs-heading-anchor" href="#Target-tree">Target tree</a><a id="Target-tree-1"></a><a class="docs-heading-anchor-permalink" href="#Target-tree" title="Permalink"></a></h3><h3 id="Source-tree"><a class="docs-heading-anchor" href="#Source-tree">Source tree</a><a id="Source-tree-1"></a><a class="docs-heading-anchor-permalink" href="#Source-tree" title="Permalink"></a></h3><h3 id="Interaction-list"><a class="docs-heading-anchor" href="#Interaction-list">Interaction list</a><a id="Interaction-list-1"></a><a class="docs-heading-anchor-permalink" href="#Interaction-list" title="Permalink"></a></h3><h3 id="Cone-domains"><a class="docs-heading-anchor" href="#Cone-domains">Cone domains</a><a id="Cone-domains-1"></a><a class="docs-heading-anchor-permalink" href="#Cone-domains" title="Permalink"></a></h3><h3 id="IFGFOp"><a class="docs-heading-anchor" href="#IFGFOp"><code>IFGFOp</code></a><a id="IFGFOp-1"></a><a class="docs-heading-anchor-permalink" href="#IFGFOp" title="Permalink"></a></h3></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="references/">References »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.15 on <span class="colophon-date" title="Wednesday 13 April 2022 11:50">Wednesday 13 April 2022</span>. Using Julia version 1.7.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
